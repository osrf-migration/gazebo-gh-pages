{"pagelen": 50, "values": [{"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "de4206af18d7", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/de4206af18d7.json"}, "html": {"href": "#!/osrf/gazebo/commits/de4206af18d7"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "f3a62b47f63b", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/f3a62b47f63b"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/f3a62b47f63b"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "MERGED", "author": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "date": "2018-05-07T07:27:57.669273+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/63346079.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-63346079"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Hi Michael, thanks for reviewing this! Yes this issue was a bit of a head-buster :wink: Thanks also for your additional comment, it will help others who want to undertand what's going on with this transport code. I haven't added more info in the description in order to not make the text even longer and deter people from reading it at all ;-D\n\nThe code is still not nice, as you pointed out. But for same reasons you mentioned \\(it would have to be re-designed\\), I opted for this minimal-change patch. When migrating to `ign-transport` this will anyway be resolved.", "markup": "markdown", "html": "<p>Hi Michael, thanks for reviewing this! Yes this issue was a bit of a head-buster <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f609.png\" alt=\"\ud83d\ude09\" title=\":wink:\" data-emoji-short-name=\":wink:\" /> Thanks also for your additional comment, it will help others who want to undertand what's going on with this transport code. I haven't added more info in the description in order to not make the text even longer and deter people from reading it at all ;-D</p>\n<p>The code is still not nice, as you pointed out. But for same reasons you mentioned (it would have to be re-designed), I opted for this minimal-change patch. When migrating to <code>ign-transport</code> this will anyway be resolved.</p>", "type": "rendered"}, "created_on": "2018-05-04T05:05:23.542121+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-05-04T05:05:23.614642+00:00", "type": "pullrequest_comment", "id": 63346079}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"approval": {"date": "2018-05-04T00:55:07.183766+00:00", "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "user": {"display_name": "Michael Grey", "uuid": "{c1cdfe52-2887-474c-ae99-72fdc53a59c9}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc1cdfe52-2887-474c-ae99-72fdc53a59c9%7D"}, "html": {"href": "https://bitbucket.org/%7Bc1cdfe52-2887-474c-ae99-72fdc53a59c9%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:67759e29-d1df-465f-868d-047738e36fc9/d42d74cf-c1bd-4431-8288-07f543bbe325/128"}}, "nickname": "mxgrey", "type": "user", "account_id": "557058:67759e29-d1df-465f-868d-047738e36fc9"}}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/63338469.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-63338469"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Thanks for the thorough explanation! This must have been a perplexing issue when you ran into it.\n\nI think I understand the problem, and this proposed fix makes sense, especially protecting the `pubIds` object with a mutex every time that it's being used.\n\nI had to flex my brain quite a bit in order to grok this line: `this->pubIds[*pubIter] = std::max(1, expRemoteCalls);`. In case it's helpful for others, I'll try to explain my understanding of it, and @JenniferBuehler (or anyone else) can correct me if I'm wrong:\n\n* We need to make sure that `this->pubIds[*pubIter]` gets deleted\n* If any remote subscribers exist, they will try to automatically deal with deleting it (in this case, `expRemoteCalls >= 1`)\n    * If none of the remote subscriptions change between `int expRemoteCalls = this->publication->GetCallbackCount();` and `int result = this->publication->Publish(*iter, ...`, then `this->pubIds[*pubIter]` will automatically be deleted by `OnPublishComplete(~)`.\n        * `int diff = result - expRemoteCalls;` will evaluate to zero, so we will skip the block inside of `if(diff < 0)`, which is okay because we don't need it.\n    * If new remote subscribers show up between `int expRemoteCalls = this->publication->GetCallbackCount();` and `int result = this->publication->Publish(*iter, ...`, then the value of `this->pubIds[*pubIter]` will easily decrement below zero and get automatically deleted.\n        * Some newer remote subscribers might miss the message, but that's what they get for showing up late.\n        * `int diff = result - expRemoteCalls;` will evaluate to greater than zero, so we will skip the block inside of `if(diff < 0)`, which is okay because we don't need it.\n    * If some remote subscribers are deleted between `int expRemoteCalls = this->publication->GetCallbackCount();` and `int result = this->publication->Publish(*iter, ...`, then `this->pubIds[*pubIter]` will not automatically be deleted by `OnPublishComplete(~)`\n        * Each time a remote subscriber calls `OnPublishComplete(~)`, it will think that there are still other remote subscribers that need to get the message, so it won't be deleted by `OnPublishComplete(~)`.\n        * `int diff = result - expRemoteCalls;` will evaluate to less than zero, so we will run the block inside of `if(diff < 0)`, because we need to manually delete `this->pubIds[*pubiter]`.\n            * We will reduce `this->pubIds[*pubIter]` by how much our initial expected remote subscriber count was off by.\n            * This is subtracted in a thread-safe way to avoid race conditions.\n            * If all the expected remote subscribers have seen the message (`this->pubIds[*pubIter] <= 0`), we delete it now.\n            * If some of the expected remote subscribers haven't seen the message yet (`this->pubIds[*pubIter] > 0`), allow `OnPublishComplete(~)` to take care of it whenever the count drops all the way\n                * Since we've applied the correction term (`diff`) to `this->pubIds[*pubIter]`, we should now get the correct behavior out of `OnPublishComplete(~)`.\n\n* If no remote subscribers exist, `this->pubIds[*pubIter]` must be deleted in this function (in this case, `expRemoteCalls == 0`)\n    * We will set `expRemoteCalls` to `1`, so that the following control flow works:\n        * If no remote subscriptions were added, `int diff = result - expRemoteCalls;` will evaluate to `-1`, so we will enter `if(diff < 0)` and manually delete `this->pubIds[*pubIter]`\n            * The previous bullet point would not work if we had left `expRemoteCalls` as `0` instead of making it `1`, because it would not have known the difference between the expected number of remote subscribers being the same as the actual (in which case no manual deletion is needed) or there being no remote subscribers at all (in which case, we need to manually delete).\n    * If remote subscriptions were added, `this->pubIds[*pubIter]` will definitely get automatically deleted.\n    * Remote subscriptions could not have been deleted, because there weren't any to begin with.\n\nThere are probably some loose threads and unfortunate edge cases still in this (like messages getting dropped for new subscribers), but I'm confident that these proposed changes at least fix the specific issue that they're intended to address. I think to fix this system any further would require a major design change, which we already have in `ign-transport`, so there's not much sense in doing it for `gazebo/transport`.\n\nIn other words, these changes look good to me.", "markup": "markdown", "html": "<p>Thanks for the thorough explanation! This must have been a perplexing issue when you ran into it.</p>\n<p>I think I understand the problem, and this proposed fix makes sense, especially protecting the <code>pubIds</code> object with a mutex every time that it's being used.</p>\n<p>I had to flex my brain quite a bit in order to grok this line: <code>this-&gt;pubIds[*pubIter] = std::max(1, expRemoteCalls);</code>. In case it's helpful for others, I'll try to explain my understanding of it, and @JenniferBuehler (or anyone else) can correct me if I'm wrong:</p>\n<ul>\n<li>We need to make sure that <code>this-&gt;pubIds[*pubIter]</code> gets deleted</li>\n<li>\n<p>If any remote subscribers exist, they will try to automatically deal with deleting it (in this case, <code>expRemoteCalls &gt;= 1</code>)</p>\n<ul>\n<li>If none of the remote subscriptions change between <code>int expRemoteCalls = this-&gt;publication-&gt;GetCallbackCount();</code> and <code>int result = this-&gt;publication-&gt;Publish(*iter, ...</code>, then <code>this-&gt;pubIds[*pubIter]</code> will automatically be deleted by <code>OnPublishComplete(~)</code>.<ul>\n<li><code>int diff = result - expRemoteCalls;</code> will evaluate to zero, so we will skip the block inside of <code>if(diff &lt; 0)</code>, which is okay because we don't need it.</li>\n</ul>\n</li>\n<li>If new remote subscribers show up between <code>int expRemoteCalls = this-&gt;publication-&gt;GetCallbackCount();</code> and <code>int result = this-&gt;publication-&gt;Publish(*iter, ...</code>, then the value of <code>this-&gt;pubIds[*pubIter]</code> will easily decrement below zero and get automatically deleted.<ul>\n<li>Some newer remote subscribers might miss the message, but that's what they get for showing up late.</li>\n<li><code>int diff = result - expRemoteCalls;</code> will evaluate to greater than zero, so we will skip the block inside of <code>if(diff &lt; 0)</code>, which is okay because we don't need it.</li>\n</ul>\n</li>\n<li>If some remote subscribers are deleted between <code>int expRemoteCalls = this-&gt;publication-&gt;GetCallbackCount();</code> and <code>int result = this-&gt;publication-&gt;Publish(*iter, ...</code>, then <code>this-&gt;pubIds[*pubIter]</code> will not automatically be deleted by <code>OnPublishComplete(~)</code><ul>\n<li>Each time a remote subscriber calls <code>OnPublishComplete(~)</code>, it will think that there are still other remote subscribers that need to get the message, so it won't be deleted by <code>OnPublishComplete(~)</code>.</li>\n<li><code>int diff = result - expRemoteCalls;</code> will evaluate to less than zero, so we will run the block inside of <code>if(diff &lt; 0)</code>, because we need to manually delete <code>this-&gt;pubIds[*pubiter]</code>.<ul>\n<li>We will reduce <code>this-&gt;pubIds[*pubIter]</code> by how much our initial expected remote subscriber count was off by.</li>\n<li>This is subtracted in a thread-safe way to avoid race conditions.</li>\n<li>If all the expected remote subscribers have seen the message (<code>this-&gt;pubIds[*pubIter] &lt;= 0</code>), we delete it now.</li>\n<li>If some of the expected remote subscribers haven't seen the message yet (<code>this-&gt;pubIds[*pubIter] &gt; 0</code>), allow <code>OnPublishComplete(~)</code> to take care of it whenever the count drops all the way<ul>\n<li>Since we've applied the correction term (<code>diff</code>) to <code>this-&gt;pubIds[*pubIter]</code>, we should now get the correct behavior out of <code>OnPublishComplete(~)</code>.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>If no remote subscribers exist, <code>this-&gt;pubIds[*pubIter]</code> must be deleted in this function (in this case, <code>expRemoteCalls == 0</code>)</p>\n<ul>\n<li>We will set <code>expRemoteCalls</code> to <code>1</code>, so that the following control flow works:<ul>\n<li>If no remote subscriptions were added, <code>int diff = result - expRemoteCalls;</code> will evaluate to <code>-1</code>, so we will enter <code>if(diff &lt; 0)</code> and manually delete <code>this-&gt;pubIds[*pubIter]</code><ul>\n<li>The previous bullet point would not work if we had left <code>expRemoteCalls</code> as <code>0</code> instead of making it <code>1</code>, because it would not have known the difference between the expected number of remote subscribers being the same as the actual (in which case no manual deletion is needed) or there being no remote subscribers at all (in which case, we need to manually delete).</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>If remote subscriptions were added, <code>this-&gt;pubIds[*pubIter]</code> will definitely get automatically deleted.</li>\n<li>Remote subscriptions could not have been deleted, because there weren't any to begin with.</li>\n</ul>\n</li>\n</ul>\n<p>There are probably some loose threads and unfortunate edge cases still in this (like messages getting dropped for new subscribers), but I'm confident that these proposed changes at least fix the specific issue that they're intended to address. I think to fix this system any further would require a major design change, which we already have in <code>ign-transport</code>, so there's not much sense in doing it for <code>gazebo/transport</code>.</p>\n<p>In other words, these changes look good to me.</p>", "type": "rendered"}, "created_on": "2018-05-04T00:55:01.590243+00:00", "user": {"display_name": "Michael Grey", "uuid": "{c1cdfe52-2887-474c-ae99-72fdc53a59c9}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc1cdfe52-2887-474c-ae99-72fdc53a59c9%7D"}, "html": {"href": "https://bitbucket.org/%7Bc1cdfe52-2887-474c-ae99-72fdc53a59c9%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:67759e29-d1df-465f-868d-047738e36fc9/d42d74cf-c1bd-4431-8288-07f543bbe325/128"}}, "nickname": "mxgrey", "type": "user", "account_id": "557058:67759e29-d1df-465f-868d-047738e36fc9"}, "updated_on": "2018-05-04T00:55:01.637956+00:00", "type": "pullrequest_comment", "id": 63338469}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"approval": {"date": "2018-03-12T19:22:39.487487+00:00", "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/58590960.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-58590960"}}, "parent": {"id": 58024913, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/58024913.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-58024913"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "looks good", "markup": "markdown", "html": "<p>looks good</p>", "type": "rendered"}, "created_on": "2018-03-12T19:21:06.147026+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-12T19:21:06.157655+00:00", "type": "pullrequest_comment", "id": 58590960}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/58024913.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-58024913"}}, "parent": {"id": 57834844, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57834844.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57834844"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "thanks, new build:\n\n* https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/828/", "markup": "markdown", "html": "<p>thanks, new build:</p>\n<ul>\n<li><a href=\"https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/828/\" rel=\"nofollow\" class=\"ap-connect-link\">https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/828/</a></li>\n</ul>", "type": "rendered"}, "created_on": "2018-03-06T10:12:14.801879+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-06T10:12:14.804829+00:00", "type": "pullrequest_comment", "id": 58024913}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57834844.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57834844"}}, "parent": {"id": 57825987, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57825987.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57825987"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Oups, I always forget that before pushing :flushed: Fixed.", "markup": "markdown", "html": "<p>Oups, I always forget that before pushing <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f633.png\" alt=\"\ud83d\ude33\" title=\":flushed:\" data-emoji-short-name=\":flushed:\" /> Fixed.</p>", "type": "rendered"}, "created_on": "2018-03-03T08:48:36.190142+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-03-03T08:48:36.248306+00:00", "type": "pullrequest_comment", "id": 57834844}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "43aba6951708", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/43aba6951708.json"}, "html": {"href": "#!/osrf/gazebo/commits/43aba6951708"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "f3a62b47f63b", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/f3a62b47f63b"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/f3a62b47f63b"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "OPEN", "author": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "date": "2018-03-03T03:16:04.944316+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57825987.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57825987"}}, "parent": {"id": 57777230, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57777230.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57777230"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "there's a few cppcheck errors:\n\n* https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/820/cppcheckResult/", "markup": "markdown", "html": "<p>there's a few cppcheck errors:</p>\n<ul>\n<li><a href=\"https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/820/cppcheckResult/\" rel=\"nofollow\" class=\"ap-connect-link\">https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/820/cppcheckResult/</a></li>\n</ul>", "type": "rendered"}, "created_on": "2018-03-02T22:15:54.845700+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-02T22:15:54.850500+00:00", "type": "pullrequest_comment", "id": 57825987}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57778211.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57778211"}}, "parent": {"id": 57745349, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745349.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745349"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Thanks! I've fixed the things you commented on.", "markup": "markdown", "html": "<p>Thanks! I've fixed the things you commented on.</p>", "type": "rendered"}, "created_on": "2018-03-02T10:39:08.789595+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-03-02T10:39:08.820457+00:00", "type": "pullrequest_comment", "id": 57778211}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "43aba6951708", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/43aba6951708.json"}, "html": {"href": "#!/osrf/gazebo/commits/43aba6951708"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "4d6b0d3236bf", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/4d6b0d3236bf"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/4d6b0d3236bf"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "OPEN", "author": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "date": "2018-03-02T10:38:36.839058+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57777230.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57777230"}}, "parent": {"id": 57745742, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745742.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745742"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Oh.. oups :wink: [https://build.osrfoundation.org/job/gazebo-ci-pr\\_any/829/](https://build.osrfoundation.org/job/gazebo-ci-pr_any/829/)", "markup": "markdown", "html": "<p>Oh.. oups <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f609.png\" alt=\"\ud83d\ude09\" title=\":wink:\" data-emoji-short-name=\":wink:\" /> <a data-is-external-link=\"true\" href=\"https://build.osrfoundation.org/job/gazebo-ci-pr_any/829/\" rel=\"nofollow\">https://build.osrfoundation.org/job/gazebo-ci-pr_any/829/</a></p>", "type": "rendered"}, "created_on": "2018-03-02T10:31:05.492663+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-03-02T10:31:05.553326+00:00", "type": "pullrequest_comment", "id": 57777230}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "43aba6951708", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/43aba6951708.json"}, "html": {"href": "#!/osrf/gazebo/commits/43aba6951708"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "1ea1248b2a10", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/1ea1248b2a10"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/1ea1248b2a10"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "OPEN", "author": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "date": "2018-03-02T10:25:11.065192+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745742.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745742"}}, "parent": {"id": 57745723, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745723.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745723"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/819/", "markup": "markdown", "html": "<p><a href=\"https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/819/\" rel=\"nofollow\" class=\"ap-connect-link\">https://build.osrfoundation.org/job/gazebo-ci-pr_any-xenial-amd64-gpu-none/819/</a></p>", "type": "rendered"}, "created_on": "2018-03-02T01:19:58.585397+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-02T01:19:58.588157+00:00", "type": "pullrequest_comment", "id": 57745742}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745723.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745723"}}, "parent": {"id": 57743171, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57743171.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57743171"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "I think those builds are using an old branch name", "markup": "markdown", "html": "<p>I think those builds are using an old branch name</p>", "type": "rendered"}, "created_on": "2018-03-02T01:19:36.034916+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-02T01:19:36.038149+00:00", "type": "pullrequest_comment", "id": 57745723}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57745349.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57745349"}}, "parent": {"id": 57743171, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57743171.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57743171"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "I just made a few more comments, but I've confirmed that the new test fails without the fix in `Publisher::SendMessage()` and passes with the fix.", "markup": "markdown", "html": "<p>I just made a few more comments, but I've confirmed that the new test fails without the fix in <code>Publisher::SendMessage()</code> and passes with the fix.</p>", "type": "rendered"}, "created_on": "2018-03-02T01:11:00.632816+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-02T01:11:00.635642+00:00", "type": "pullrequest_comment", "id": 57745349}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744485.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744485"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "need 3 slashes for doxygen: `/// \\brief ...`", "markup": "markdown", "html": "<p>need 3 slashes for doxygen: <code>/// \\brief ...</code></p>", "type": "rendered"}, "created_on": "2018-03-02T00:52:59.473330+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:52:59.476493+00:00", "type": "pullrequest_comment", "id": 57744485}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744384.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744384"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "this line can be removed", "markup": "markdown", "html": "<p>this line can be removed</p>", "type": "rendered"}, "created_on": "2018-03-02T00:50:29.616880+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:50:29.620142+00:00", "type": "pullrequest_comment", "id": 57744384}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744303.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744303"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "`ASSERT_TRUE(IsParent());`", "markup": "markdown", "html": "<p><code>ASSERT_TRUE(IsParent());</code></p>", "type": "rendered"}, "created_on": "2018-03-02T00:48:37.300092+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:49:06.977657+00:00", "type": "pullrequest_comment", "id": 57744303}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744261.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744261"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "`ASSERT_FALSE(gazebo::transport::is_stopped());`", "markup": "markdown", "html": "<p><code>ASSERT_FALSE(gazebo::transport::is_stopped());</code></p>", "type": "rendered"}, "created_on": "2018-03-02T00:47:28.236754+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:48:55.212914+00:00", "type": "pullrequest_comment", "id": 57744261}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744286.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744286"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "interfer -> interfere", "markup": "markdown", "html": "<p>interfer -&gt; interfere</p>", "type": "rendered"}, "created_on": "2018-03-02T00:48:06.609343+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:48:06.612966+00:00", "type": "pullrequest_comment", "id": 57744286}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744231.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744231"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "`Publishing.cc` doesn't exist. I think you mean `Publication.cc`?", "markup": "markdown", "html": "<p><code>Publishing.cc</code> doesn't exist. I think you mean <code>Publication.cc</code>?</p>", "type": "rendered"}, "created_on": "2018-03-02T00:46:28.722924+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:46:28.726291+00:00", "type": "pullrequest_comment", "id": 57744231}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57744135.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57744135"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "this should be split onto multiple lines", "markup": "markdown", "html": "<p>this should be split onto multiple lines</p>", "type": "rendered"}, "created_on": "2018-03-02T00:43:39.665627+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:43:39.669050+00:00", "type": "pullrequest_comment", "id": 57744135}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57743979.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57743979"}}, "parent": {"id": 57742681, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57742681.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57742681"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": ":smile: ", "markup": "markdown", "html": "<p><img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f604.png\" alt=\"\ud83d\ude04\" title=\":smile:\" data-emoji-short-name=\":smile:\" /> </p>", "type": "rendered"}, "created_on": "2018-03-02T00:40:05.487929+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-02T00:40:05.491312+00:00", "type": "pullrequest_comment", "id": 57743979}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57743171.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57743171"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Queued [another build](https://build.osrfoundation.org/job/gazebo-ci-pr_any/828/) after merging with newest default and two edits in response to comments by @scpeters ", "markup": "markdown", "html": "<p>Queued <a data-is-external-link=\"true\" href=\"https://build.osrfoundation.org/job/gazebo-ci-pr_any/828/\" rel=\"nofollow\">another build</a> after merging with newest default and two edits in response to comments by @scpeters </p>", "type": "rendered"}, "created_on": "2018-03-02T00:20:55.124579+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-03-02T00:20:55.179582+00:00", "type": "pullrequest_comment", "id": 57743171}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57742997.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57742997"}}, "parent": {"id": 57618515, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57618515.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57618515"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Done", "markup": "markdown", "html": "<p>Done</p>", "type": "rendered"}, "created_on": "2018-03-02T00:17:27.762722+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2018-03-02T00:17:27.796553+00:00", "type": "pullrequest_comment", "id": 57742997}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "43aba6951708", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/43aba6951708.json"}, "html": {"href": "#!/osrf/gazebo/commits/43aba6951708"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "2bdbd28b37a1", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/2bdbd28b37a1"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/2bdbd28b37a1"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "OPEN", "author": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "date": "2018-03-02T00:17:05.663915+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57742681.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57742681"}}, "parent": {"id": 57738273, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57738273.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57738273"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Aahh I completely forgot I'd already done that :open_mouth:  So long ago! Sorry never mind. So yes, this can be removed now.", "markup": "markdown", "html": "<p>Aahh I completely forgot I'd already done that <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f62e.png\" alt=\"\ud83d\ude2e\" title=\":open_mouth:\" data-emoji-short-name=\":open_mouth:\" />  So long ago! Sorry never mind. So yes, this can be removed now.</p>", "type": "rendered"}, "created_on": "2018-03-02T00:10:21.442763+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2018-03-02T00:10:21.492736+00:00", "type": "pullrequest_comment", "id": 57742681}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57738273.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57738273"}}, "parent": {"id": 57617795, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57617795.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57617795"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "See also my comment above... this is in there because the test currently can only be done manually, a remote subscriber has to be started by the user.  You mean that we can now use a new process fork to start a remote subscriber?", "markup": "markdown", "html": "<p>See also my comment above... this is in there because the test currently can only be done manually, a remote subscriber has to be started by the user.  You mean that we can now use a new process fork to start a remote subscriber?</p>", "type": "rendered"}, "created_on": "2018-03-01T22:47:39.499930+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2018-03-01T22:48:27.884982+00:00", "type": "pullrequest_comment", "id": 57738273}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57618515.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57618515"}}, "parent": {"id": 42972219, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972219.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972219"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "yeah, I think the ifdef's can be removed", "markup": "markdown", "html": "<p>yeah, I think the ifdef's can be removed</p>", "type": "rendered"}, "created_on": "2018-03-01T00:48:52.003055+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "updated_on": "2018-03-01T00:48:52.006028+00:00", "type": "pullrequest_comment", "id": 57618515}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/57617795.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-57617795"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "I think this change is no longer necessary since the process fork was added to the test", "markup": "markdown", "html": "<p>I think this change is no longer necessary since the process fork was added to the test</p>", "type": "rendered"}, "created_on": "2018-03-01T00:32:54.797998+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2018-03-01T00:32:54.801296+00:00", "type": "pullrequest_comment", "id": 57617795}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"update": {"description": "I believe I stumbled over a bug in the transport system which sometimes stalls the message publishing of a `transport::Publisher`. This can be triggered when using `Publisher::Publish()` in blocking mode (parameter \\_block=true).\r\n\r\nThis is a multi-threading related issue which I think should be fixed in any case (also for non-blocking mode).\r\n\r\nIt's probably easiest to explain the issue on code snippets of the existing code.\r\n\r\nFor easy reference: `OnPublishComplete` is the function which should be called at the time just after a message has just been sent (which can happen from another thread). It decreases a counter for this message ID, and deletes the entry from the buffer if the counter reaches zero. This basically helps to keep track on the number of times this function was called for each message.   \r\nNote that the `this->pubIds` map is protected by `this->mutex`.\r\n\r\n```C++\r\nvoid Publisher::OnPublishComplete(uint32_t _id) \r\n{ \r\n boost::mutex::scoped_lock lock(this->mutex); \r\n \r\n std::map<uint32_t, int>::iterator iter = this->pubIds.find(_id); \r\n if (iter != this->pubIds.end() && (--iter->second) <= 0) \r\n this->pubIds.erase(iter); \r\n} \r\n```\r\n\r\nThen there is the function `SendMessage()` which is called from `Publisher::Publish()` when in blocking mode. The blocking is supposed to wait until the message is \"written out\" (*minor side issue:* this is a phrasing in the comments that could maybe be changed, because the actual \"writing out\" still happens asynchronously from `Publication`, so a call of `Publisher::Publish(..block=true)` will not actually guarantee the message has been written out!).\r\n\r\n```C++\r\nvoid Publisher::SendMessage()                                                   \r\n{                                                                               \r\n  std::list<MessagePtr> localBuffer;                                            \r\n  std::list<uint32_t> localIds;                                                 \r\n                                                                                \r\n  {                                                                             \r\n    boost::mutex::scoped_lock lock(this->mutex);                                \r\n    if (!this->pubIds.empty() || this->messages.empty())                        \r\n      return;                                                                   \r\n                                                                                \r\n    for (unsigned int i = 0; i < this->messages.size(); ++i)                    \r\n    {                                                                           \r\n      this->pubId = (this->pubId + 1) % 10000;                                  \r\n      this->pubIds[this->pubId] = 0;                                            \r\n      localIds.push_back(this->pubId);                                          \r\n    }                                                                           \r\n                                                                                \r\n    std::copy(this->messages.begin(), this->messages.end(),                     \r\n        std::back_inserter(localBuffer));                                       \r\n    this->messages.clear();                                                     \r\n  }\r\n  ...\r\n```\r\n\r\nThis first part basically has copied everything into local buffers (presumably to avoid blocking the mutex too long and to avoid deadlocks). This is all trivial, except one crucial thing to note here: If there are any message ID's still hanging around in `this->pubID`, this function won't do anything more - no \"writing out\" happens. This can be interpreted as *\"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the `this->messages `buffer until the next time SendMessage() is called\"*. I guess this was done in order to ensure that messages are sent out in the right order (?).\r\n\r\nNext, the copies of `messages` and `pubIDs` are used to actually publish the messages using `transport::Publication::Publish()`, which will trigger a call to `OnPublishComplete()` **once for each subscriber callback** of `Publication`. A subscriber callback however is used for **remote subscribers** only (started in a separate terminal). It's probably possible to add subscriber callbacks in different ways too. But here it's only important that if we have local subscribers (as in all the gtests as far as I can see), we won't have a subscriber callback.   \r\n*Bottom line:* `Publication::Publish()` basically returns the number of times the `OnPublishComplete()` callback has been triggered per remote subscriber (Note that with remote subscribers, the actual calling of OnPublishComplete() happens asynchronously: the subscriber callback `SubscriptionTransport::HandleData()` only enqueues the message).\r\n\r\n```C++\r\n  ...\r\n  // Only send messages if there is something to send                           \r\n  if (!localBuffer.empty())                                                     \r\n  {                                                                             \r\n    std::list<uint32_t>::iterator pubIter = localIds.begin();                   \r\n                                                                                \r\n    // Send all the current messages                                            \r\n    for (std::list<MessagePtr>::iterator iter = localBuffer.begin();            \r\n        iter != localBuffer.end(); ++iter, ++pubIter)                           \r\n    {                                                                           \r\n      // Send the latest message.                                               \r\n      int result = this->publication->Publish(*iter,                            \r\n          boost::bind(&Publisher::OnPublishComplete, this, _1), *pubIter);\r\n      ...\r\n```\r\n\r\nSo I believe the intention is to expect a certain amount of calls to `OnPublishComplete()`. To achieve this, the `this->pubIds` is set with the message ID as key, and as a value the expected number of calls:\r\n\r\n```C++\r\n      ...\r\n      if (result > 0)                                                           \r\n        this->pubIds[*pubIter] = result;                                        \r\n      else                                                                      \r\n        this->pubIds.erase(*pubIter);                                           \r\n    }\r\n    ...\r\n```\r\n\r\nPlease correct me if I have misunderstood this intention.\r\n\r\nThere is a few issues with the above bit of code:\r\n\r\n*  `pubIds` is not mutex protected as it should be.\r\n* If we have only local subscribers, the counter should still be set to 1, because `OnPublishComplete` will still be called once.\r\n* It is possible (randomly due to threads) that by the time `this->pubIds` is set to the value of `result`, `OnPublishComplete()` has already been called, and the entry in `pubIds` has already been erased. This has happened to me, which brought me onto this issue in the first place. In this case, if we have remote subscribers, we will just re-add it here, and **it will never be removed again**! Which will in turn cause all future calls to `SendMessage()` to not do anything, as per condition `!this->pubIds.empty()` in the beginning of the function. So we have a \"publishing dead-end\".\r\n\r\nThe tricky bit is that this only happens when using remote subscribers, which may be a reason why it has gone unnoticed in the automated tests so far? Because if there are only local subscribers, `result` is 0, and the buffer will just always be cleared (it will not really be used actually). So the issue won't arise at all.\r\n\r\nThis PR proposes a way to fix this up, though it's not ready to be merged as there could be better (but more intrusive) solutions to this. I've put it up for discussion. I added some more comments to the code to explain what's going on. \r\n\r\nI've also added a test file which still requires to start a remote publisher manually (by `gz topic -e <topic>`), which is something that should be simulated instead.  \r\nYou can trigger the failure case by commenting `TEMP_NEW_APPROACH_TEST` in Publisher.cc, which will then use the old code. You may have to try a few times because of the randomness, sometimes it can still succeed with the old code.\r\n\r\nOne last thing: It would be important to let the user know that if they are only using \"blocking\" calls to `Publisher::Publish()`, it is *not* guaranteed that the message has actually already been sent. It may still sit in the queue, and it may actually be necessary to call `Publisher::SendMessage()` again to make sure the queue has been emptied. See also comments in the code.", "title": "Fixing issue in which publishing of messages gets stuck.", "destination": {"commit": {"hash": "43aba6951708", "type": "commit", "links": {"self": {"href": "data/repositories/osrf/gazebo/commit/43aba6951708.json"}, "html": {"href": "#!/osrf/gazebo/commits/43aba6951708"}}}, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "branch": {"name": "default"}}, "reason": "", "source": {"commit": {"hash": "92e9d409c51b", "type": "commit", "links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo/commit/92e9d409c51b"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo/commits/92e9d409c51b"}}}, "repository": {"links": {"self": {"href": "https://api.bitbucket.org/2.0/repositories/JenniferBuehler/gazebo"}, "html": {"href": "https://bitbucket.org/JenniferBuehler/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{11522dd5-648b-4e9e-b908-d3e1170ba728}ts=c_plus_plus"}}, "type": "repository", "name": "gazebo", "full_name": "JenniferBuehler/gazebo", "uuid": "{11522dd5-648b-4e9e-b908-d3e1170ba728}"}, "branch": {"name": "transport_sendmessage_blocking_issue"}}, "state": "OPEN", "author": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "date": "2018-02-28T01:57:30.662037+00:00"}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972525.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972525"}}, "parent": {"id": 42963259, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42963259.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42963259"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Yes, maybe that's what was originally intended? Although it's kind of the opposite effect...", "markup": "markdown", "html": "<p>Yes, maybe that's what was originally intended? Although it's kind of the opposite effect...</p>", "type": "rendered"}, "created_on": "2017-08-17T02:31:13.603182+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:31:13.647695+00:00", "type": "pullrequest_comment", "id": 42972525}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972477.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972477"}}, "parent": {"id": 42966264, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42966264.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42966264"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Fixed", "markup": "markdown", "html": "<p>Fixed</p>", "type": "rendered"}, "created_on": "2017-08-17T02:29:10.083484+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:29:10.117854+00:00", "type": "pullrequest_comment", "id": 42972477}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972472.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972472"}}, "parent": {"id": 42966279, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42966279.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42966279"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Fixed", "markup": "markdown", "html": "<p>Fixed</p>", "type": "rendered"}, "created_on": "2017-08-17T02:28:59.521730+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:28:59.562398+00:00", "type": "pullrequest_comment", "id": 42972472}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972346.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972346"}}, "parent": {"id": 42875976, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42875976.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42875976"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Hmmmm according to the comment yes... that would have been a silly mistake! Maybe I've thought something else of this at the time, can't remember. Anyway that's only there as a failsafe in case the person testing this changes `numMsgs` to something larger than `bufferSize`, so it wouldn't have had an effect in the tests up until this point, as both numbers are currently the same.\n\nAnyway I've changed this as `std::max` doesn't make sense.", "markup": "markdown", "html": "<p>Hmmmm according to the comment yes... that would have been a silly mistake! Maybe I've thought something else of this at the time, can't remember. Anyway that's only there as a failsafe in case the person testing this changes <code>numMsgs</code> to something larger than <code>bufferSize</code>, so it wouldn't have had an effect in the tests up until this point, as both numbers are currently the same.</p>\n<p>Anyway I've changed this as <code>std::max</code> doesn't make sense.</p>", "type": "rendered"}, "created_on": "2017-08-17T02:24:41.141508+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:24:41.193661+00:00", "type": "pullrequest_comment", "id": 42972346}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972219.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972219"}}, "parent": {"id": 42961126, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42961126.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42961126"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Ok, can do! Does anyone else still need it for testing? If not, I'll remove it.", "markup": "markdown", "html": "<p>Ok, can do! Does anyone else still need it for testing? If not, I'll remove it.</p>", "type": "rendered"}, "created_on": "2017-08-17T02:19:48.549741+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "updated_on": "2017-08-17T02:19:48.594028+00:00", "type": "pullrequest_comment", "id": 42972219}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972195.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972195"}}, "parent": {"id": 42962778, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42962778.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42962778"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Agree... anyone else comments on this? I can add that change to this PR.", "markup": "markdown", "html": "<p>Agree... anyone else comments on this? I can add that change to this PR.</p>", "type": "rendered"}, "created_on": "2017-08-17T02:19:14.553565+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:19:14.595407+00:00", "type": "pullrequest_comment", "id": 42972195}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42972073.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42972073"}}, "parent": {"id": 42876117, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42876117.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42876117"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Yes, that's about what I've experienced", "markup": "markdown", "html": "<p>Yes, that's about what I've experienced</p>", "type": "rendered"}, "created_on": "2017-08-17T02:15:49.000333+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-17T02:15:49.046958+00:00", "type": "pullrequest_comment", "id": 42972073}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42966279.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42966279"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "`else if (this->IsChild())`", "markup": "markdown", "html": "<p><code>else if (this-&gt;IsChild())</code></p>", "type": "rendered"}, "created_on": "2017-08-16T22:59:17.822371+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2017-08-16T22:59:17.825724+00:00", "type": "pullrequest_comment", "id": 42966279}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42966264.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42966264"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "`if (this->IsParent())`", "markup": "markdown", "html": "<p><code>if (this-&gt;IsParent())</code></p>", "type": "rendered"}, "created_on": "2017-08-16T22:58:54.140653+00:00", "user": {"display_name": "Steve Peters", "uuid": "{2ccfed09-18b8-4921-8d58-15ef01092802}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D"}, "html": {"href": "https://bitbucket.org/%7B2ccfed09-18b8-4921-8d58-15ef01092802%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/1fb4816dad9e68337d3096f750951f6cd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsSP-1.png"}}, "nickname": "Steven Peters", "type": "user", "account_id": "557058:5de38267-b118-494c-aa76-4fab35448816"}, "inline": {}, "updated_on": "2017-08-16T22:58:54.147495+00:00", "type": "pullrequest_comment", "id": 42966264}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42963259.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42963259"}}, "parent": {"id": 42701435, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42701435.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42701435"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "That check does seem odd. It would almost make more sense if it were in a while loop at the end of `SendMessage` to make it block.", "markup": "markdown", "html": "<p>That check does seem odd. It would almost make more sense if it were in a while loop at the end of <code>SendMessage</code> to make it block.</p>", "type": "rendered"}, "created_on": "2017-08-16T21:44:09.544520+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T21:44:09.547177+00:00", "type": "pullrequest_comment", "id": 42963259}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42962778.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42962778"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Since this may or may not process any messages depending on whether pubIds remain, I wonder whether it would be safe to cap the number of messages to handle in one call at 10000. That way the pubIds can't loop around. It may be a trivial point depending on how unlikely it is to overflow 10000.", "markup": "markdown", "html": "<p>Since this may or may not process any messages depending on whether pubIds remain, I wonder whether it would be safe to cap the number of messages to handle in one call at 10000. That way the pubIds can't loop around. It may be a trivial point depending on how unlikely it is to overflow 10000.</p>", "type": "rendered"}, "created_on": "2017-08-16T21:35:47.760530+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T21:35:47.763120+00:00", "type": "pullrequest_comment", "id": 42962778}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42961964.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42961964"}}, "parent": {"id": 42876117, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42876117.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42876117"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "The test succeeded with the fix 10/10 times for me.", "markup": "markdown", "html": "<p>The test succeeded with the fix 10/10 times for me.</p>", "type": "rendered"}, "created_on": "2017-08-16T21:21:38.855583+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T21:21:38.857923+00:00", "type": "pullrequest_comment", "id": 42961964}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42961126.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42961126"}}, "parent": {"id": 36527251, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/36527251.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-36527251"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "I think it is fine to remove the preprocessor conditional and just leave the new approach.", "markup": "markdown", "html": "<p>I think it is fine to remove the preprocessor conditional and just leave the new approach.</p>", "type": "rendered"}, "created_on": "2017-08-16T21:06:04.462574+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "updated_on": "2017-08-16T21:07:47.406324+00:00", "type": "pullrequest_comment", "id": 42961126}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42876238.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42876238"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "When the publisher get stuck, it tends to fall through this loop without `pub->GetOutgoingCount` reaching `0` in addition to `g_receivedPosesStamped` not reaching `numMsgs`.", "markup": "markdown", "html": "<p>When the publisher get stuck, it tends to fall through this loop without <code>pub-&gt;GetOutgoingCount</code> reaching <code>0</code> in addition to <code>g_receivedPosesStamped</code> not reaching <code>numMsgs</code>.</p>", "type": "rendered"}, "created_on": "2017-08-16T00:26:51.082113+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T00:26:51.084573+00:00", "type": "pullrequest_comment", "id": 42876238}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42876117.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42876117"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "I ran this test 10 times without the proposed fix and it failed 4 times and succeeded 6 times.  Is that similar to what you observed or should it fail every time?", "markup": "markdown", "html": "<p>I ran this test 10 times without the proposed fix and it failed 4 times and succeeded 6 times.  Is that similar to what you observed or should it fail every time?</p>", "type": "rendered"}, "created_on": "2017-08-16T00:22:08.082822+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T00:22:08.085489+00:00", "type": "pullrequest_comment", "id": 42876117}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42875976.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42875976"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Should this be `std::min`?", "markup": "markdown", "html": "<p>Should this be <code>std::min</code>?</p>", "type": "rendered"}, "created_on": "2017-08-16T00:16:20.544990+00:00", "user": {"display_name": "Peter Horak", "uuid": "{c72abe74-c12a-4128-a6fc-94f3844ac8ef}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D"}, "html": {"href": "https://bitbucket.org/%7Bc72abe74-c12a-4128-a6fc-94f3844ac8ef%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a/87d803b7-3e50-40c1-8159-a5c20abd84ea/128"}}, "nickname": "pchorak", "type": "user", "account_id": "557058:451ed60b-3cfa-4a97-b4d3-a3fc34c2b21a"}, "inline": {}, "updated_on": "2017-08-16T00:16:20.548050+00:00", "type": "pullrequest_comment", "id": 42875976}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}, {"comment": {"links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/42701435.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-42701435"}}, "parent": {"id": 40329486, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657/comments/40329486.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657/_/diff#comment-40329486"}}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}, "content": {"raw": "Good point, I wasn't 100% sure why this has been done either, I've commented on that in the PR description (which is admittedly painfully long)...\n\n`This can be interpreted as \"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the this->messages buffer until the next time SendMessage() is called\". I guess this was done in order to ensure that messages are sent out in the right order (?).`\n\nIt's maybe to prevent calling `Publish()` at all in the first place while there are any messages still hanging around which haven't been finalised with `OnPublishComplete` yet, but I could not find any documentation about why things are set up this way either.", "markup": "markdown", "html": "<p>Good point, I wasn't 100% sure why this has been done either, I've commented on that in the PR description (which is admittedly painfully long)...</p>\n<p><code>This can be interpreted as \"if there are any messages which have not finished publishing yet, don't proceed, and instead keep them in the this-&gt;messages buffer until the next time SendMessage() is called\". I guess this was done in order to ensure that messages are sent out in the right order (?).</code></p>\n<p>It's maybe to prevent calling <code>Publish()</code> at all in the first place while there are any messages still hanging around which haven't been finalised with <code>OnPublishComplete</code> yet, but I could not find any documentation about why things are set up this way either.</p>", "type": "rendered"}, "created_on": "2017-08-12T04:55:14.621991+00:00", "user": {"display_name": "Jennifer Buehler", "uuid": "{5949baad-8c43-4d52-9a82-bb8c3511fed8}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D"}, "html": {"href": "https://bitbucket.org/%7B5949baad-8c43-4d52-9a82-bb8c3511fed8%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/b28ae0e95eada6ee16f0860c1fa59fdcd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsJB-4.png"}}, "nickname": "JenniferBuehler", "type": "user", "account_id": "557058:96bd489a-ec14-4a06-8d31-7bb6d46d1209"}, "inline": {}, "updated_on": "2017-08-12T04:55:14.708738+00:00", "type": "pullrequest_comment", "id": 42701435}, "pull_request": {"type": "pullrequest", "id": 2657, "links": {"self": {"href": "data/repositories/osrf/gazebo/pullrequests/2657.json"}, "html": {"href": "#!/osrf/gazebo/pull-requests/2657"}}, "title": "Fixing issue in which publishing of messages gets stuck."}}], "next": "data/repositories/osrf/gazebo/pullrequests/2657/activity_ctx=xkFgpsBI7.json"}