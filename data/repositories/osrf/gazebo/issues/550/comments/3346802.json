{"links": {"self": {"href": "data/repositories/osrf/gazebo/issues/550/comments/3346802.json"}, "html": {"href": "#!/osrf/gazebo/issues/550#comment-3346802"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/gazebo/issues/550.json"}}, "type": "issue", "id": 550, "repository": {"links": {"self": {"href": "data/repositories/osrf/gazebo.json"}, "html": {"href": "#!/osrf/gazebo"}, "avatar": {"href": "data/bytebucket.org/ravatar/{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}ts=1694483"}}, "type": "repository", "name": "gazebo", "full_name": "osrf/gazebo", "uuid": "{51a0cd5d-8697-4eb1-8b08-e919ee881e1c}"}, "title": "Arbitrary model properties"}, "content": {"raw": "I think he's suggesting something similar to what I was suggesting for friction in my comment to issue #474.\nThe idea would be to have materials that are being accessed by different sensors. So for example right now a normal camera sensor uses all the visual texture (diffuse, specular, normal, ...) to return its sensor readings, but for detecting vegetation for example people make use of infrared light to calculate the NDVI used for detecting (healthy) vegetation. Now you don't want to simulate infrared reflectance and everything that goes along with it so you would simply have material for your objects that represents the NDVI which would then be accessible by a sensor.\n\nThis approach would also be useful to simulate intensity readings (reflectance) for LIDAR sensors properly.\n\nLong story short: \nMaterials that are applied like the visual textures but only visible to certain sensors.\n\nAt least that's how I understood his request / how I would imagine it to work. :)", "markup": "markdown", "html": "<p>I think he's suggesting something similar to what I was suggesting for friction in my comment to issue <a href=\"#!/osrf/gazebo/issues/474/create-a-materials-tag-for-collision\" rel=\"nofollow\" title=\"Create a materials tag for collision bodies analogous to visual materials\" class=\"ap-connect-link\">#474</a>.\nThe idea would be to have materials that are being accessed by different sensors. So for example right now a normal camera sensor uses all the visual texture (diffuse, specular, normal, ...) to return its sensor readings, but for detecting vegetation for example people make use of infrared light to calculate the NDVI used for detecting (healthy) vegetation. Now you don't want to simulate infrared reflectance and everything that goes along with it so you would simply have material for your objects that represents the NDVI which would then be accessible by a sensor.</p>\n<p>This approach would also be useful to simulate intensity readings (reflectance) for LIDAR sensors properly.</p>\n<p>Long story short: \nMaterials that are applied like the visual textures but only visible to certain sensors.</p>\n<p>At least that's how I understood his request / how I would imagine it to work. :)</p>", "type": "rendered"}, "created_on": "2013-03-08T01:48:15.552050+00:00", "user": {"display_name": "Thomas Koletschka", "uuid": "{b33092ac-6376-48d1-9803-d9e6de445d1a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bb33092ac-6376-48d1-9803-d9e6de445d1a%7D"}, "html": {"href": "https://bitbucket.org/%7Bb33092ac-6376-48d1-9803-d9e6de445d1a%7D/"}, "avatar": {"href": "https://bitbucket.org/account/thomasko/avatar/"}}, "nickname": "thomasko", "type": "user", "account_id": null}, "updated_on": null, "type": "issue_comment", "id": 3346802}